{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow DeepDream tutorial.\n",
    "https://www.tensorflow.org/tutorials/generative/deepdream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import IPython.display as display\n",
    "import PIL.Image\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import glob\n",
    "\n",
    "\n",
    "images = glob.glob(\"CH13 Dream/*.JPG\")\n",
    "#images is a list of filenames\n",
    "    \n",
    "    \n",
    "# Download an image and read it into a NumPy array.\n",
    "def download(image, max_dim=None):\n",
    "    with open(image, 'rb') as file:\n",
    "        img = PIL.Image.open(file)\n",
    "        img_arr = np.array(img) #have to define nparray whule image is open rather than in 'return' line\n",
    "    return img_arr\n",
    "\n",
    "# Normalize an image\n",
    "def deprocess(img):\n",
    "    img = 255*(img + 1.0)/2.0\n",
    "    return tf.cast(img, tf.uint8)\n",
    "\n",
    "# Display an image\n",
    "def show(img):\n",
    "    display.display(PIL.Image.fromarray(np.array(img)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare feature extraction model using InceptionV3\n",
    "\n",
    "The idea in DeepDream is to choose a layer (or layers) and maximize the \"loss\" in a way that the image increasingly \"excites\" the layers. \n",
    "\n",
    "The InceptionV3 architecture is quite large. The layers of interest are those where the convolutions are concatenated. There are 11 of these layers in InceptionV3, named 'mixed0' though 'mixed10'. Using different layers will result in different dream-like images. Deeper layers respond to higher-level features (such as eyes and faces), while earlier layers respond to simpler features (such as edges, shapes, and textures). Feel free to experiment with the layers selected below, but keep in mind that deeper layers (those with a higher index) will take longer to train on since the gradient computation is deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "\n",
    "base_model = InceptionV3(include_top=False, weights='imagenet')\n",
    "\n",
    "# Calculate loss. Usually want to minimize, but for DeepDream we want to maximize it.\n",
    "\n",
    "def calc_loss(img, model):\n",
    "    # Pass forward the image through the model to retrieve the activations.\n",
    "    # Converts the image into a batch of size 1.\n",
    "    img_batch = tf.expand_dims(img, axis=0)\n",
    "    layer_activations = model(img_batch)\n",
    "    if len(layer_activations) == 1:\n",
    "        layer_activations = [layer_activations]\n",
    "\n",
    "    losses = []\n",
    "    for act in layer_activations:\n",
    "        loss = tf.math.reduce_mean(act)\n",
    "        losses.append(loss)\n",
    "\n",
    "    return  tf.reduce_sum(losses)\n",
    "\n",
    "# Collect everything nicely into DeepDream class\n",
    "\n",
    "class DeepDream(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=(\n",
    "            tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=[], dtype=tf.int32),\n",
    "            tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
    "        )\n",
    "    \n",
    "    def __call__(self, img, steps, step_size):\n",
    "        print(\"Tracing\")\n",
    "        loss = tf.constant(0.0)\n",
    "        for n in tf.range(steps):\n",
    "            with tf.GradientTape() as tape:\n",
    "            # This needs gradients relative to `img`\n",
    "            # `GradientTape` only watches `tf.Variable`s by default\n",
    "                tape.watch(img)\n",
    "                loss = calc_loss(img, self.model)\n",
    "\n",
    "            # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
    "            gradients = tape.gradient(loss, img)\n",
    "\n",
    "            # Normalize the gradients.\n",
    "            gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "\n",
    "            # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
    "            # You can update the image by directly adding the gradients (because they're the same shape!)\n",
    "            img = img + gradients*step_size\n",
    "            img = tf.clip_by_value(img, -1, 1)\n",
    "\n",
    "        return loss, img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "\n",
    "def run_deep_dream_simple(img, steps=100, step_size=0.01):\n",
    "    # Convert from uint8 to the range expected by the model.\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    img = tf.convert_to_tensor(img)\n",
    "    step_size = tf.convert_to_tensor(step_size)\n",
    "    steps_remaining = steps\n",
    "    step = 0\n",
    "    while steps_remaining:\n",
    "        if steps_remaining>100:\n",
    "            run_steps = tf.constant(100)\n",
    "        else:\n",
    "            run_steps = tf.constant(steps_remaining)\n",
    "        steps_remaining -= run_steps\n",
    "        step += run_steps\n",
    "\n",
    "        loss, img = deepdream(img, run_steps, tf.constant(step_size))\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        show(deprocess(img))\n",
    "        print (\"Step {}, loss {}\".format(step, loss))\n",
    "\n",
    "    result = deprocess(img)\n",
    "    display.clear_output(wait=True)\n",
    "    show(result)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good, but...\n",
    "The output is noisy (this could be addressed with a tf.image.total_variation loss). <br>\n",
    "The image is low resolution. <br>\n",
    "The patterns appear like they're all happening at the same granularity. <br>\n",
    "One approach that addresses all these problems is applying gradient ascent at different scales. This will allow patterns generated at smaller scales to be incorporated into patterns at higher scales and filled in with additional detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: perform gradient ascent then increase size of image (octave) and repeat for multiple octaves.\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "OCTAVE_SCALE = 1.30\n",
    "\n",
    "img = tf.constant(np.array(original_img))\n",
    "base_shape = tf.shape(img)[:-1]\n",
    "float_base_shape = tf.cast(base_shape, tf.float32)\n",
    "\n",
    "for n in range(-2, 3):\n",
    "    new_shape = tf.cast(float_base_shape*(OCTAVE_SCALE**n), tf.int32)\n",
    "\n",
    "    img = tf.image.resize(img, new_shape).numpy()\n",
    "\n",
    "    img = run_deep_dream_simple(img=img, steps=50, step_size=0.01)\n",
    "\n",
    "display.clear_output(wait=True)\n",
    "img = tf.image.resize(img, base_shape)\n",
    "img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
    "show(img)\n",
    "\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even better, but will take too long on large images and/or many octaves.\n",
    "\n",
    "Fix: Split into tiles and work tile by tile. Randomly shift to prevent tile seams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First implement random shift:\n",
    "\n",
    "def random_roll(img, maxroll):\n",
    "    # Randomly shift the image to avoid tiled boundaries.\n",
    "    shift = tf.random.uniform(shape=[2], minval=-maxroll, maxval=maxroll, dtype=tf.int32)\n",
    "    shift_down, shift_right = shift[0],shift[1] \n",
    "    img_rolled = tf.roll(tf.roll(img, shift_right, axis=1), shift_down, axis=0)\n",
    "    return shift_down, shift_right, img_rolled\n",
    "\n",
    "shift_down, shift_right, img_rolled = random_roll(np.array(original_img), 512)\n",
    "show(img_rolled)\n",
    "\n",
    "# Tiled gradient version of deepdream function defined above:\n",
    "\n",
    "class TiledGradients(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=(\n",
    "            tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=[], dtype=tf.int32),)\n",
    "        )\n",
    "    \n",
    "    def __call__(self, img, tile_size=512):\n",
    "        shift_down, shift_right, img_rolled = random_roll(img, tile_size)\n",
    "\n",
    "        # Initialize the image gradients to zero.\n",
    "        gradients = tf.zeros_like(img_rolled)\n",
    "            \n",
    "        # Skip the last tile, unless there's only one tile.\n",
    "        xs = tf.range(0, img_rolled.shape[0], tile_size)[:-1]\n",
    "        if not tf.cast(len(xs), bool):\n",
    "            xs = tf.constant([0])\n",
    "        ys = tf.range(0, img_rolled.shape[1], tile_size)[:-1]\n",
    "        if not tf.cast(len(ys), bool):\n",
    "            ys = tf.constant([0])\n",
    "                        \n",
    "        #testing lines below\n",
    "        tape = tf.GradientTape()\n",
    "        loss = calc_loss(img, self.model)\n",
    "\n",
    "        for x in xs:\n",
    "            for y in ys:\n",
    "            # Calculate the gradients for this tile.\n",
    "                with tf.GradientTape() as tape:\n",
    "                    # This needs gradients relative to `img_rolled`.\n",
    "                    # `GradientTape` only watches `tf.Variable`s by default.\n",
    "                    tape.watch(img_rolled)\n",
    "\n",
    "                    # Extract a tile out of the image.\n",
    "                    img_tile = img_rolled[x:x+tile_size, y:y+tile_size]\n",
    "                    loss = calc_loss(img_tile, self.model)\n",
    "                    \n",
    "                # Update the image gradients for this tile.\n",
    "                gradients = gradients + tape.gradient(loss, img_rolled)\n",
    "\n",
    "        # Undo the random shift applied to the image and its gradients.\n",
    "        gradients = tf.roll(tf.roll(gradients, -shift_right, axis=1), -shift_down, axis=0)\n",
    "\n",
    "        # Normalize the gradients.\n",
    "        gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "\n",
    "        return gradients "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deep_dream_with_octaves(img, steps_per_octave=100, step_size=0.01, octaves=range(-2,3), octave_scale=1.3):\n",
    "    base_shape = tf.shape(img)\n",
    "    \n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    initial_shape = img.shape[:-1]\n",
    "    img = tf.image.resize(img, initial_shape)\n",
    "    \n",
    "    for octave in octaves:\n",
    "        # Scale the image based on the octave\n",
    "        new_size = tf.cast(tf.convert_to_tensor(base_shape[:-1]), tf.float32)*(octave_scale**octave)\n",
    "        img = tf.image.resize(img, tf.cast(new_size, tf.int32))\n",
    "\n",
    "        for step in range(steps_per_octave):\n",
    "            gradients = get_tiled_gradients(img)\n",
    "            img = img + gradients*step_size\n",
    "            img = tf.clip_by_value(img, -1, 1)\n",
    "            \n",
    "            if step % 10 == 0:\n",
    "                display.clear_output(wait=True)\n",
    "                show(deprocess(img))\n",
    "                print (\"Octave {}, Step {}\".format(octave, step))\n",
    "\n",
    "    result = deprocess(img)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile all cells above, adjust everything in code block below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with the number of octaves, octave scale, and activated layers. \n",
    "# Consider different images. Relevant code below.\n",
    "\n",
    "original_img = download(images[19], max_dim=500)\n",
    "show(original_img)\n",
    "\n",
    "# Layers can be modified: choices range from mixed0 to mixed10\n",
    "#names = ['mixed6', 'mixed1']\n",
    "names = ['mixed4', 'mixed8']\n",
    "layers = [base_model.get_layer(name).output for name in names]\n",
    "\n",
    "# Create feature extraction model\n",
    "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "\n",
    "deepdream = DeepDream(dream_model)\n",
    "\n",
    "#simple version 1, uncomment to run\n",
    "#dream_img = run_deep_dream_simple(img=original_img, steps=100, step_size=0.01)\n",
    "\n",
    "get_tiled_gradients = TiledGradients(dream_model)\n",
    "\n",
    "img = run_deep_dream_with_octaves(img=original_img, step_size=0.01)\n",
    "\n",
    "#display.clear_output(wait=True)\n",
    "#img = tf.image.resize(img, base_shape)\n",
    "#img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
    "#show(img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
